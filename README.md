# texts_continuous
Scrapy crawler that collects all the blogtexts for the continuousscraper study. 

The scraped texts are saved in an SQLite database.

Start the crawling process simply by typing `python processcontrol.py`. You receive an email once the process starts, 
and when it is finished. 
